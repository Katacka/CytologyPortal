#include <iostream>
#include <stdio.h>
#include "opencv2/opencv.hpp"
#include "VLFeatWrapper.cpp"

using namespace std;

namespace segment
{
    class SegmenterTools
    {
    public:
        /*
        runQuickshift takes an image and params and runs Quickshift on it, using the VL_Feat implementation
        Returns:
            cv::Mat = image after quickshift is applied
        Params:
            cv::Mat img = the image
            int kernelsize = the kernel or window size of the quickshift applied
            int maxdist = the largest distance a pixel can be from it's root
        */
        cv::Mat runQuickshift(cv::Mat img, int kernelsize, int maxdist, bool debug = false)
        {
            int channels = img.channels();
            int width = img.cols;
            int height = img.rows;

            cv::Mat tempMat;
            img.copyTo(tempMat);
            tempMat.convertTo(tempMat, CV_64FC3, 1/255.0);
            double* cvimg = (double*) tempMat.data;
            double* vlimg = (double*) calloc(channels*width*height, sizeof(double));

            // create VLFeatWrapper object
            segment::VLFeatWrapper vlf_wrapper = segment::VLFeatWrapper(width, height, channels);
            vlf_wrapper.debug = debug;
            vlf_wrapper.verifyVLFeat();

            // apply quickshift from VLFeat
            vlf_wrapper.convertOPENCV_VLFEAT(cvimg, vlimg);
            int superpixelcount = vlf_wrapper.quickshift(vlimg, kernelsize, maxdist);
            vlf_wrapper.convertVLFEAT_OPENCV(vlimg, cvimg);

            cv::Mat postQuickShift = cv::Mat(height, width, CV_64FC3, cvimg);
            cv::Mat outimg;
            postQuickShift.copyTo(outimg);
            outimg.convertTo(outimg, CV_8UC3, 255);
            free(vlimg);

            if(debug) printf("Super pixels found via quickshift: %i\n", superpixelcount);
            return outimg;
        }

        /*
        runCanny runs canny edge detection on an image, and dilates and erodes it to close holes
        Returns:
            cv::Mat = edges found post dilate/erode
        Params:
            cv::Mat img = image to find edged in
            int threshold1 = first threshold for the hysteresis procedure.
            int threshold2 = second threshold for the hysteresis procedure.
        */
        cv::Mat runCanny(cv::Mat img, int threshold1, int threshold2)
        {
            cv::Mat postEdgeDetection;
            img.copyTo(postEdgeDetection);
            cv::Mat blurred;
            cv::blur(img, blurred, cv::Size(3,3));
            cv::Canny(blurred, postEdgeDetection, threshold1, threshold2);

            // TODO these values for dilate and erode possibly should be configurable
            cv::dilate(postEdgeDetection, postEdgeDetection, cv::Mat(), cv::Point(-1, -1), 2);
            cv::erode(postEdgeDetection, postEdgeDetection, cv::Mat(), cv::Point(-1, -1), 2);

            return postEdgeDetection;
        }

        /*
        runGmm creates 2 Gaussian Mixture Models, one for cell pixels and one for background pixels,
        then returns the result of the labels generated by these models
        Returns:
            cv::Mat = labels found per pixel
        Params:
            cv::Mat img = image to process
            vector<vector<cv::Point> > hulls = convex hulls to provide initial labeling
            int maxGmmIterations = maximum number of iterations to allow the gmm to train
        */
        cv::Mat runGmm(cv::Mat img, vector<vector<cv::Point> > hulls, int maxGmmIterations)
        {
            int width = img.cols;
            int height = img.rows;

            cv::Mat gray;
            img.convertTo(gray, CV_8U);
            cv::cvtColor(gray, gray, CV_BGR2GRAY);
            gray.convertTo(gray, CV_64F, 1/255.0);

            // create initial probabilities based on convex hulls
            float initialProbs[width*height][2];
            for(int row=0; row < height; row++)
            {
                for(int col=0; col < width; col++)
                {
                    for(unsigned int hullIndex=0; hullIndex < hulls.size(); hullIndex++)
                    {
                        if(cv::pointPolygonTest(hulls[hullIndex], cv::Point2f(row, col), false) >= 0)
                        {
                            initialProbs[row + col*height][0] = 1;
                            initialProbs[row + col*height][1] = 0;
                        }
                        else
                        {
                            initialProbs[row + col*height][0] = 0;
                            initialProbs[row + col*height][1] = 1;
                        }
                    }
                }
            }
            gray = gray.reshape(0, gray.rows*gray.cols);
            cv::Mat initialProbMat(width*height, 2, CV_32F, initialProbs);

            cv::Mat outputProbs;
            cv::Mat labels;
            cv::Ptr<cv::ml::EM> cell_gmm;
            cv::TermCriteria termCrit = cv::TermCriteria();
            termCrit.type = cv::TermCriteria::COUNT;
            termCrit.maxCount = maxGmmIterations;
            cell_gmm = cv::ml::EM::create();
            cell_gmm->setTermCriteria(termCrit);
            cell_gmm->setClustersNumber(2);
            cell_gmm->trainM(gray, initialProbMat, cv::noArray(), labels, outputProbs);

            labels = labels.reshape(0, img.rows);
            cv::Mat outimg;
            labels.convertTo(outimg, CV_8U, 255);

            return outimg;
        }

        /*
        runMser takes an image and params and runs MSER algorithm on it, for nuclei detection
        Return:
            vector<vector<cv::Point> > = stable regions found
        Params:
            cv::Mat img = the image
            int delta = the # of iterations a region must remain stable
            int minArea = the minimum number of pixels for a viable region
            int maxArea = the maximum number of pixels for a viable region
            double maxVariation = the max amount of variation allowed in regions
            double minDiversity = the min diversity allowed in regions
        */
        vector<vector<cv::Point> > runMser(cv::Mat img, int delta, int minArea, int maxArea,
            double maxVariation, double minDiversity)
        {
            cv::Ptr<cv::MSER> ms = cv::MSER::create(delta, minArea, maxArea, maxVariation, minDiversity);
            cv::Mat tmp;
            img.convertTo(tmp, CV_8U);
            cv::cvtColor(tmp, tmp, CV_BGR2GRAY);
            vector<vector<cv::Point> > regions;
            vector<cv::Rect> mser_bbox;

            ms->detectRegions(tmp, regions, mser_bbox);

            return regions;
        }

        /*
        findFinalClumpBoundaries takes an image and a threshold and returns all the contours whose
        size is greater than the threshold
        Returns:
            vector<vector<cv::Point> > = the contours found
        Params:
            cv::Mat img = the input image
            int minAreaThreshold = the minimum area, all contours smaller than this are discarded
        */
        vector<vector<cv::Point> > findFinalClumpBoundaries(cv::Mat img, int minAreaThreshold)
        {
            // opencv wants to find white object on a black background,
            // so we want to invert the labels before findContours
            cv::bitwise_not(img, img);

            vector<vector<cv::Point> > contours;
            cv::findContours(img, contours, CV_RETR_EXTERNAL, CV_CHAIN_APPROX_NONE);
            vector<vector<cv::Point> > clumpBoundaries = vector<vector<cv::Point> >();
            for(unsigned int i=0; i<contours.size(); i++)
            {
                vector<cv::Point> contour = contours[i];
                double area = cv::contourArea(contour);
                if(area > minAreaThreshold)
                {
                    clumpBoundaries.push_back(contour);
                }
            }

            return clumpBoundaries;
        }

        /*
        extractClump takes an image, contours from the image, and an index, then masks the image to show only
        the contour/clump specified by the index, crops, and returns the image
        Returns:
            cv::Mat = the image of the specified clump - masked out and cropped from the original image
        Params:
            cv::Mat img = the original image
            vector<vector<cv::Point> > clumpBoundaries = the clumpBoundaries in the image
            int clumpIndex = the index in clumpBoundaries of the clump to extract
        */
        cv::Mat extractClump(cv::Mat img, vector<vector<cv::Point> > clumpBoundaries, int clumpIndex)
        {
            // create a mask for each clump and apply it
            cv::Mat mask = cv::Mat::zeros(img.rows, img.cols, CV_8U);
            cv::drawContours(mask, clumpBoundaries, clumpIndex, cv::Scalar(255), CV_FILLED);
            cv::Mat fullMasked = cv::Mat(img.rows, img.cols, CV_8U);
            fullMasked.setTo(cv::Scalar(255, 0, 255));
            img.copyTo(fullMasked, mask);
            // invert the mask and then invert the black pixels in the extracted image
            cv::bitwise_not(mask, mask);
            cv::bitwise_not(fullMasked, fullMasked, mask);

            // grab the bounding rect for each clump
            cv::Rect rect = cv::boundingRect(clumpBoundaries[clumpIndex]);

            // create mat of each clump
            cv::Mat clump = cv::Mat(fullMasked, rect);

            clump.convertTo(clump, CV_8UC3);
            return clump;
        }
    };
}
